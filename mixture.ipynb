{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13f8f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import RESULTS_FOLDER, get_config\n",
    "from file_utils import load_most_recent_results, load_most_recent_model\n",
    "from src.analysis import combine_all_trials, process_results, compute_top_codes\n",
    "import numpy as np\n",
    "from src.model import build_model\n",
    "import os\n",
    "import pickle as pk\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from src.data import get_mnist_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9277ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = load_most_recent_results(RESULTS_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "159ff6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = len(result_dict.keys())\n",
    "combined_results = combine_all_trials(result_dict)\n",
    "processed_result = process_results(combined_results)\n",
    "top_codes = compute_top_codes(result_dict[0], NUM_TOP_CODES=5)\n",
    "top_full_codes_info = top_codes['post_train_code_histogram']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c897a03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'top_codes': ['01111111-11111011',\n  '11111111-11111011',\n  '01110111-11111011',\n  '11010111-11110000',\n  '01101111-11111011'],\n 'cmass_top_code': [0.12426666666666666,\n  0.2034,\n  0.2744,\n  0.31074999999999997,\n  0.34401666666666664],\n 'mass_top_code': [0.12426666666666666,\n  0.07913333333333333,\n  0.071,\n  0.03635,\n  0.03326666666666667],\n 'ratio_1_0': 3.0944975923501135}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_full_codes_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "823c965a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['01111111-11111011',\n '11111111-11111011',\n '01110111-11111011',\n '11010111-11110000',\n '01101111-11111011']"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_codes = top_full_codes_info['top_codes']\n",
    "top_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d264c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_most_recent_model(RESULTS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9d3c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_code_to_list(code_string):\n",
    "    list_codes_per_layer=  []\n",
    "    list_string_per_layer = code_string.split('-')\n",
    "    for string_per_layer in list_string_per_layer:\n",
    "        list_codes_per_layer.append([int(c) for c in string_per_layer])\n",
    "    print(code_string, '->',list_codes_per_layer )\n",
    "    return list_codes_per_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c2e59b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01111111-11111011 -> [[0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "test = string_code_to_list(top_codes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9b1b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSoftMax(torch.nn.Module):\n",
    "    def __init__(self, input_size, weights, bias, output_size = 10):\n",
    "        super(LinearSoftMax, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.weights = torch.from_numpy(weights)\n",
    "        self.bias = torch.from_numpy(bias)\n",
    "        self.linear = torch.nn.Linear(self.input_size, output_size)\n",
    "        # nn.Parameter(F.softmax(self.layer_weights,dim=0))\n",
    "        with torch.no_grad():\n",
    "            self.linear.weight = torch.nn.Parameter(self.weights)\n",
    "            self.linear.bias = torch.nn.Parameter(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.linear(x)\n",
    "        log_out = F.log_softmax(x, dim=1)\n",
    "        return log_out\n",
    "\n",
    "# Accepts a relu activation code and generates a linear softmax model from it.\n",
    "def NN_to_logreg(model, list_codes_per_layer):\n",
    "    model.eval()\n",
    "    weights = []\n",
    "    biases = []\n",
    "    for i, layer_code in enumerate(list_codes_per_layer):\n",
    "        # build matrix to cancel off ReLU's\n",
    "        layer = model.first_layer if i == 0 else model.list_layers[i - 1] # fix this so we can access the layers directly in model.list_layer\n",
    "        cancel_matrix = np.eye(layer.weight.shape[0])\n",
    "        for r in range(len(layer_code)):\n",
    "            cancel_matrix[r, r] = layer_code[r]\n",
    "        new_weight = np.matmul(cancel_matrix, layer.weight.detach().numpy())\n",
    "        new_bias = np.matmul(cancel_matrix, layer.bias.detach().numpy())\n",
    "        weights.append(new_weight)\n",
    "        biases.append(new_bias)\n",
    "    # Add last layer fed into softmax\n",
    "    weights.append(model.last_layer.weight.detach().numpy())\n",
    "    biases.append(model.last_layer.bias.detach().numpy())\n",
    "\n",
    "    # Combine all weights and biases into a single\n",
    "    combined_weight = weights[len(weights) - 1]\n",
    "    combined_bias = biases[len(biases) - 1]\n",
    "    for i in range(len(weights) - 2, -1, -1):\n",
    "        combined_bias = combined_bias + np.matmul(combined_weight, biases[i]) # This line should go before the below one\n",
    "        combined_weight = np.matmul(combined_weight, weights[i])\n",
    "    return LinearSoftMax(model.input_size, combined_weight, combined_bias)\n",
    "\n",
    "\n",
    "linearized = NN_to_logreg(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "871879c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[53], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m output \u001B[38;5;241m=\u001B[39m linearized(X)\n\u001B[1;32m      6\u001B[0m pred \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mint\u001B[39m(out\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m      7\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m out \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;241m1\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m1\u001B[39m]]\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;43mprint\u001B[39;49m(pred)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[53], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m output \u001B[38;5;241m=\u001B[39m linearized(X)\n\u001B[1;32m      6\u001B[0m pred \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mint\u001B[39m(out\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m      7\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m out \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;241m1\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m1\u001B[39m]]\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;43mprint\u001B[39;49m(pred)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/IntelliJIdea2022.2/plugins/python/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/IntelliJIdea2022.2/plugins/python/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_mnist_data(get_config())\n",
    "\n",
    "for X, y in test_loader:\n",
    "    X = X.double()\n",
    "    output = linearized(X)\n",
    "    pred = [int(out.cpu().detach().numpy())\n",
    "            for out in output.data.max(1, keepdim=True)[1]]\n",
    "    print(pred)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1e4da9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('first_layer.weight',\n",
       "              tensor([[ 0.0348,  0.0054,  0.0562,  ...,  0.0215,  0.0411,  0.0022],\n",
       "                      [-0.0271, -0.0093,  0.0090,  ...,  0.0196, -0.0156,  0.0276],\n",
       "                      [-0.0236,  0.0028, -0.0280,  ..., -0.0048, -0.0084, -0.0630],\n",
       "                      ...,\n",
       "                      [-0.0767, -0.0373, -0.0776,  ..., -0.0936, -0.0500, -0.0382],\n",
       "                      [-0.0531, -0.0543, -0.0130,  ..., -0.0515, -0.0503, -0.0757],\n",
       "                      [-0.0551, -0.0915, -0.0704,  ..., -0.1047, -0.0995, -0.1102]])),\n",
       "             ('first_layer.bias',\n",
       "              tensor([-0.0552,  0.0068,  0.0495,  0.0316, -0.0067,  0.1698,  0.1308,  0.1733])),\n",
       "             ('last_layer.weight',\n",
       "              tensor([[ 1.4483,  0.0207, -1.3224, -0.3605, -0.0021,  0.0046,  0.5091, -0.4646],\n",
       "                      [-1.5897, -0.8683,  0.9067,  1.2290, -0.1305,  0.0967,  0.4637,  0.1305],\n",
       "                      [ 0.3136, -0.0405, -0.6119,  0.2937, -0.9546,  0.0264,  1.3021,  0.8476],\n",
       "                      [ 0.1039, -0.8577,  0.4506, -0.4304,  0.2470, -0.0949,  0.3044,  1.2426],\n",
       "                      [-0.4635,  1.2563, -0.2177, -0.9437,  0.5287,  0.1565, -0.3059, -1.3468],\n",
       "                      [ 0.5441, -0.3788, -0.7826,  0.8469,  0.9418,  0.0144, -0.1803, -0.5459],\n",
       "                      [-0.0773,  0.6886, -1.7200,  0.2917,  0.6798,  0.0332, -0.4649,  0.3103],\n",
       "                      [-0.2062, -0.3620,  1.2170, -1.0141, -1.2671,  0.4623,  1.0036, -0.5232],\n",
       "                      [ 0.4512, -0.7870,  0.2712,  1.6058,  0.0152,  0.1817, -1.3020,  0.0619],\n",
       "                      [ 0.1549,  0.0610,  1.2527, -0.7614,  0.2662,  0.1031, -1.7395, -0.5483]])),\n",
       "             ('last_layer.bias',\n",
       "              tensor([-1.0102, -0.1867, -1.4507, -0.4004,  1.8127,  0.7448, -0.4016,  0.6991,\n",
       "                      -0.8012,  0.0805]))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc8cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c6e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb79da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbf824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98740de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c58fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
